{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **NPFL087 Project**\n",
        "## **Spanish <-> Greek speech dataset**\n",
        "\n",
        "> **Objective**: achievement of a big enough dataset of parallel speech adherences in the order they were spoken from parallel speech data, via usage of recognizers of Spanish and Greek and alignments done at the transcription text level.\n",
        "\n",
        "> **Author**: Adriana R.Flórez ([adrirflorez@gmail.com](mailto:adrirflorez@gmail.com))\n",
        "\n",
        "> **Course**: _NPFL087_ Statistical Machine Translation\n",
        "\n"
      ],
      "metadata": {
        "id": "ZI1m_IFWcPRR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOYvVSY5_ZRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd64ec5-6425-4462-f3d1-827ca9d85376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting git+https://github.com/m-bain/whisperx.git\n",
            "  Cloning https://github.com/m-bain/whisperx.git to /tmp/pip-req-build-6j9sowxo\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperx.git /tmp/pip-req-build-6j9sowxo\n",
            "  Resolved https://github.com/m-bain/whisperx.git to commit 5012650d0f3d8966f3ea517762f952a624996d32\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ctranslate2<4.5.0 (from whisperx==3.3.4)\n",
            "  Downloading ctranslate2-4.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting faster-whisper>=1.1.1 (from whisperx==3.3.4)\n",
            "  Downloading faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.4) (3.9.1)\n",
            "Requirement already satisfied: numpy>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.4) (2.0.2)\n",
            "Collecting onnxruntime>=1.19 (from whisperx==3.3.4)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting pandas>=2.2.3 (from whisperx==3.3.4)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyannote-audio>=3.3.2 (from whisperx==3.3.4)\n",
            "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.4) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.4) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.48.0 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.4) (4.51.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<4.5.0->whisperx==3.3.4) (75.2.0)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<4.5.0->whisperx==3.3.4) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx==3.3.4) (0.31.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx==3.3.4) (0.21.1)\n",
            "Collecting av>=11 (from faster-whisper>=1.1.1->whisperx==3.3.4)\n",
            "  Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx==3.3.4) (4.67.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->whisperx==3.3.4) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->whisperx==3.3.4) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->whisperx==3.3.4) (2024.11.6)\n",
            "Collecting coloredlogs (from onnxruntime>=1.19->whisperx==3.3.4)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19->whisperx==3.3.4) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19->whisperx==3.3.4) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19->whisperx==3.3.4) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19->whisperx==3.3.4) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx==3.3.4) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx==3.3.4) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx==3.3.4) (2025.2)\n",
            "Collecting asteroid-filterbanks>=0.4 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.4) (0.8.1)\n",
            "Collecting lightning>=2.0.1 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.4) (2.3.0)\n",
            "Collecting pyannote.core>=5.0.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyannote.database>=5.0.1 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyannote.metrics>=3.2 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyannote.pipeline>=3.0.1 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
            "Collecting pytorch-metric-learning>=2.1.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.4) (13.9.4)\n",
            "Collecting semver>=3.0.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.4) (0.13.1)\n",
            "Collecting speechbrain>=1.0.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tensorboardX>=2.6 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting torch-audiomentations>=0.11.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting torchmetrics>=0.11.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.5.1->whisperx==3.3.4)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.5.1->whisperx==3.3.4)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.5.1->whisperx==3.3.4)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->whisperx==3.3.4)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->whisperx==3.3.4)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->whisperx==3.3.4)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->whisperx==3.3.4)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->whisperx==3.3.4)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->whisperx==3.3.4)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->whisperx==3.3.4)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.19->whisperx==3.3.4) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.48.0->whisperx==3.3.4) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.48.0->whisperx==3.3.4) (0.5.3)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<3.0,>=2.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4) (1.15.3)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (0.15.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4) (1.6.1)\n",
            "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4) (3.10.0)\n",
            "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->whisperx==3.3.4) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4) (2.19.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (1.17.1)\n",
            "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4) (0.2.0)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.19->whisperx==3.3.4)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->whisperx==3.3.4) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx==3.3.4) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx==3.3.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx==3.3.4) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx==3.3.4) (2025.4.26)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (3.11.15)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4) (3.2.3)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (2.0.40)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4) (3.6.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (1.5.4)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (1.20.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (1.1.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4) (3.2.2)\n",
            "Downloading ctranslate2-4.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.4/37.4 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
            "Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: whisperx, docopt, julius\n",
            "  Building wheel for whisperx (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisperx: filename=whisperx-3.3.4-py3-none-any.whl size=16482612 sha256=24acd906efe88a0a0202642406d3640273fa49256bda7bfddddb16363d6bfec6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sf5jo372/wheels/a7/c5/cb/f337e8d88ff15af9ece963912a153e4132d00e7cdd61f48416\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=015e293fc97bdf2ef471be6fd8ee976a94f67c8777b5c118ae37f0ce9d3ac830\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=852be09cd5edc5472c745aade1504c68cc4af57b4ec5729e1483a8abc0c2fbda\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
            "Successfully built whisperx docopt julius\n",
            "Installing collected packages: primePy, docopt, tensorboardX, semver, ruamel.yaml.clib, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, humanfriendly, ctranslate2, colorlog, av, ruamel.yaml, pyannote.core, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, alembic, optuna, onnxruntime, nvidia-cusolver-cu12, hyperpyyaml, pyannote.database, faster-whisper, torchmetrics, pytorch-metric-learning, pyannote.pipeline, pyannote.metrics, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, torch-audiomentations, lightning, pyannote-audio, whisperx\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.15.2 asteroid-filterbanks-0.4.0 av-14.3.0 coloredlogs-15.0.1 colorlog-6.9.0 ctranslate2-4.4.0 docopt-0.6.2 faster-whisper-1.1.1 humanfriendly-10.0 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.5.1.post0 lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.22.0 optuna-4.3.0 pandas-2.2.3 primePy-1.3 pyannote-audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.5.1.post0 pytorch-metric-learning-2.8.1 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 semver-3.0.4 speechbrain-1.0.3 tensorboardX-2.6.2.2 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchmetrics-1.7.1 whisperx-3.3.4\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Collecting git+https://github.com/SYSTRAN/faster-whisper\n",
            "  Cloning https://github.com/SYSTRAN/faster-whisper to /tmp/pip-req-build-bl83wa2m\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/SYSTRAN/faster-whisper /tmp/pip-req-build-bl83wa2m\n",
            "  Resolved https://github.com/SYSTRAN/faster-whisper to commit 700584b2e6c15825c73e232f323e4b910257fa1c\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==1.1.1) (4.4.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==1.1.1) (0.31.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==1.1.1) (0.21.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==1.1.1) (1.22.0)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==1.1.1) (14.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper==1.1.1) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper==1.1.1) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper==1.1.1) (2.0.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper==1.1.1) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.13->faster-whisper==1.1.1) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.13->faster-whisper==1.1.1) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.13->faster-whisper==1.1.1) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.13->faster-whisper==1.1.1) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.13->faster-whisper==1.1.1) (4.13.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.1.1) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.1.1) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.1.1) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.1.1) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==1.1.1) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==1.1.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==1.1.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==1.1.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==1.1.1) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper==1.1.1) (1.3.0)\n",
            "Collecting setuptools-rust\n",
            "  Downloading setuptools_rust-1.11.1-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: setuptools>=62.4 in /usr/local/lib/python3.11/dist-packages (from setuptools-rust) (75.2.0)\n",
            "Collecting semantic_version<3,>=2.8.2 (from setuptools-rust)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Downloading setuptools_rust-1.11.1-py3-none-any.whl (28 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: semantic_version, setuptools-rust\n",
            "Successfully installed semantic_version-2.10.0 setuptools-rust-1.11.1\n",
            "Collecting hf_xet\n",
            "  Downloading hf_xet-1.1.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Downloading hf_xet-1.1.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.5/25.5 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hf_xet\n",
            "Successfully installed hf_xet-1.1.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "--2025-05-16 14:35:47--  ftp://ftp.mokk.bme.hu/Hunglish/src/hunalign/latest/hunalign-1.1.tgz\n",
            "           => ‘hunalign-1.1.tgz’\n",
            "Resolving ftp.mokk.bme.hu (ftp.mokk.bme.hu)... 152.66.10.57\n",
            "Connecting to ftp.mokk.bme.hu (ftp.mokk.bme.hu)|152.66.10.57|:21... connected.\n",
            "Logging in as anonymous ... Logged in!\n",
            "==> SYST ... done.    ==> PWD ... done.\n",
            "==> TYPE I ... done.  ==> CWD (1) /Hunglish/src/hunalign/latest ... done.\n",
            "==> SIZE hunalign-1.1.tgz ... 5518673\n",
            "==> PASV ... done.    ==> RETR hunalign-1.1.tgz ... done.\n",
            "Length: 5518673 (5.3M) (unauthoritative)\n",
            "\n",
            "hunalign-1.1.tgz    100%[===================>]   5.26M  1.44MB/s    in 5.1s    \n",
            "\n",
            "2025-05-16 14:35:54 (1.04 MB/s) - ‘hunalign-1.1.tgz’ saved [5518673]\n",
            "\n",
            "hunalign-1.1/\n",
            "hunalign-1.1/src/\n",
            "hunalign-1.1/src/utils/\n",
            "hunalign-1.1/src/utils/argumentsParser.cpp\n",
            "hunalign-1.1/src/utils/timer.cpp\n",
            "hunalign-1.1/src/utils/histogram.cpp\n",
            "hunalign-1.1/src/utils/stringsAndStreams.cpp\n",
            "hunalign-1.1/src/hunalign/\n",
            "hunalign-1.1/src/hunalign/trailPostprocessors.cpp\n",
            "hunalign-1.1/src/hunalign/similarityEvaluator.cpp\n",
            "hunalign-1.1/src/hunalign/Makefile\n",
            "hunalign-1.1/src/hunalign/bloom.cpp\n",
            "hunalign-1.1/src/hunalign/TEIReader.h\n",
            "hunalign-1.1/src/hunalign/alignment.cpp\n",
            "hunalign-1.1/src/hunalign/dictionary.cpp\n",
            "hunalign-1.1/src/hunalign/oldAlignTest.cpp\n",
            "hunalign-1.1/src/hunalign/cooccurrence.cpp\n",
            "hunalign-1.1/src/hunalign/main.cpp\n",
            "hunalign-1.1/src/hunalign/dictionary.h\n",
            "hunalign-1.1/src/hunalign/dicTree.h\n",
            "hunalign-1.1/src/hunalign/similarityEvaluator.h\n",
            "hunalign-1.1/src/hunalign/networkFlow.cpp\n",
            "hunalign-1.1/src/hunalign/wordAlignment.cpp\n",
            "hunalign-1.1/src/hunalign/help.h\n",
            "hunalign-1.1/src/hunalign/alignerTool.cpp\n",
            "hunalign-1.1/src/hunalign/cooccurrenceTool.cpp\n",
            "hunalign-1.1/src/hunalign/TEIReader.cpp\n",
            "hunalign-1.1/src/hunalign/quasiDiagonal.h\n",
            "hunalign-1.1/src/hunalign/translate.cpp\n",
            "hunalign-1.1/src/hunalign/bookToMatrix.cpp\n",
            "hunalign-1.1/src/hunalign/trailPostprocessors.h\n",
            "hunalign-1.1/src/hunalign/networkFlow.h\n",
            "hunalign-1.1/src/hunalign/wordAlignment.h\n",
            "hunalign-1.1/src/hunalign/DOMTreeErrorReporter.cpp\n",
            "hunalign-1.1/src/hunalign/translate.h\n",
            "hunalign-1.1/src/hunalign/cooccurrence.h\n",
            "hunalign-1.1/src/hunalign/bloom.h\n",
            "hunalign-1.1/src/hunalign/words.h\n",
            "hunalign-1.1/src/hunalign/bookToMatrix.h\n",
            "hunalign-1.1/src/hunalign/alignment.h\n",
            "hunalign-1.1/src/include/\n",
            "hunalign-1.1/src/include/portableHash.h\n",
            "hunalign-1.1/src/include/stringsAndStreams.h\n",
            "hunalign-1.1/src/include/histogram.h\n",
            "hunalign-1.1/src/include/argumentsParser.h\n",
            "hunalign-1.1/src/include/serializeImpl.h\n",
            "hunalign-1.1/src/include/timer.h\n",
            "hunalign-1.1/data/\n",
            "hunalign-1.1/data/hungarian.aff\n",
            "hunalign-1.1/data/hungarian.dic\n",
            "hunalign-1.1/data/hu-en.dic\n",
            "hunalign-1.1/data/english.aff\n",
            "hunalign-1.1/data/english.dic\n",
            "hunalign-1.1/data/hu-en.stem.dic\n",
            "hunalign-1.1/data/null.dic\n",
            "hunalign-1.1/LICENSE\n",
            "hunalign-1.1/tools/\n",
            "hunalign-1.1/tools/stemtool\n",
            "hunalign-1.1/scripts/\n",
            "hunalign-1.1/scripts/hu.sen.one.sh\n",
            "hunalign-1.1/scripts/en.sen.one.sh\n",
            "hunalign-1.1/scripts/release.howto.txt\n",
            "hunalign-1.1/scripts/partialAlign.py\n",
            "hunalign-1.1/scripts/visualizeLadder.noshrink.awk\n",
            "hunalign-1.1/scripts/process.sh\n",
            "hunalign-1.1/scripts/visualizeAlignQuality.awk\n",
            "hunalign-1.1/scripts/tok.one.sh\n",
            "hunalign-1.1/scripts/visualizeLadder.awk\n",
            "hunalign-1.1/scripts/ladder2text.py\n",
            "hunalign-1.1/examples/\n",
            "hunalign-1.1/examples/demo.hu.stem\n",
            "hunalign-1.1/examples/demo.manual.ladder\n",
            "hunalign-1.1/examples/en.raw\n",
            "hunalign-1.1/examples/hu.raw\n",
            "hunalign-1.1/examples/demo.en.stem\n",
            "hunalign-1.1/readme.html\n",
            "/content/hunalign-1.1/src/hunalign\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o alignerTool.o alignerTool.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o alignment.o alignment.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o bloom.o bloom.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o bookToMatrix.o bookToMatrix.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o cooccurrence.o cooccurrence.cpp\n",
            "In file included from \u001b[01m\u001b[K/usr/include/c++/11/ext/hash_map:60\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K../include/portableHash.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kcooccurrence.cpp:36\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/c++/11/backward/backward_warning.h:32:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning This file includes at least one deprecated or antiquated header which may be removed without further notice at a future date. Please use a non-deprecated interface with equivalent functionality instead. For a listing of replacement headers and interfaces, consult the file backward_warning.h. To disable this warning use -Wno-deprecated. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   32 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o cooccurrenceTool.o cooccurrenceTool.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o dictionary.o dictionary.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o main.o main.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o networkFlow.o networkFlow.cpp\n",
            "In file included from \u001b[01m\u001b[K/usr/include/c++/11/ext/hash_map:60\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K../include/portableHash.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[KnetworkFlow.cpp:15\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/c++/11/backward/backward_warning.h:32:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning This file includes at least one deprecated or antiquated header which may be removed without further notice at a future date. Please use a non-deprecated interface with equivalent functionality instead. For a listing of replacement headers and interfaces, consult the file backward_warning.h. To disable this warning use -Wno-deprecated. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   32 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o oldAlignTest.o oldAlignTest.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o trailPostprocessors.o trailPostprocessors.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o translate.o translate.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o wordAlignment.o wordAlignment.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o ../utils/stringsAndStreams.o ../utils/stringsAndStreams.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o ../utils/argumentsParser.o ../utils/argumentsParser.cpp\n",
            "g++  -O9 -ffast-math -funroll-loops -I ../include  -c -o ../utils/timer.o ../utils/timer.cpp\n",
            "g++ -O9 -ffast-math -funroll-loops -I ../include -lstdc++ -o hunalign alignerTool.o alignment.o bloom.o bookToMatrix.o cooccurrence.o cooccurrenceTool.o dictionary.o main.o networkFlow.o oldAlignTest.o trailPostprocessors.o translate.o wordAlignment.o ../utils/stringsAndStreams.o ../utils/argumentsParser.o ../utils/timer.o\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# 🧠 Install WhisperX and related audio packages\n",
        "!pip install pydub\n",
        "!pip install git+https://github.com/m-bain/whisperx.git\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "# 🧠 Install Faster-Whisper\n",
        "!pip install git+https://github.com/SYSTRAN/faster-whisper\n",
        "\n",
        "# 🧰 Install setuptools-rust (required for some Whisper/WhisperX deps)\n",
        "!pip install setuptools-rust\n",
        "\n",
        "# 🔐 Hugging Face utility\n",
        "!pip install hf_xet\n",
        "\n",
        "# 📖 HunAlign\n",
        "!apt-get install -y build-essential\n",
        "!wget ftp://ftp.mokk.bme.hu/Hunglish/src/hunalign/latest/hunalign-1.1.tgz\n",
        "!tar zxvf hunalign-1.1.tgz\n",
        "%cd hunalign-1.1/src/hunalign\n",
        "!make\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ri-kU5jB-sQ",
        "outputId": "127dbba0-c22e-469d-9b8d-af2840ae5e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependency set-up checks:\n",
            "✅ PyTorch: 2.6.0+cu124\n",
            "✅ CUDA available:  True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "import torch\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "import numpy\n",
        "import pyannote.audio\n",
        "import faster_whisper\n",
        "import whisperx\n",
        "\n",
        "print(\"Dependency set-up checks:\")\n",
        "print(\"✅ PyTorch:\", torch.__version__)\n",
        "print(\"✅ CUDA available: \", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiMB2_qm_kDa"
      },
      "source": [
        "# **1. Data**\n",
        "\n",
        "Input data should be a collection of .wav audio files found in a ./data/ directory, in a specific subdirectory identified with the audio's ISO-2 language code.\n",
        "\n",
        "Output data is stored in .json, .srt and .txt formats, found in a ./transcriptions/ directory, in a specific subdirectory identified with the same language's code. Each transcription file has the same name as the .wav file it transcribes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parallel Greek <--> Spanish speech data has been downloaded from the VoxPopuli dataset for both languages, and preprocessed in order to achieve significant segments in Spanish and find their respective parallel segments in Greek, as well as a manifest \"parallel_el-es.tsv\" file that shows the correspondence between the two language audio files:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "el\tes\n",
        "data\\el_es\\el\\20090401-0900-PLENARY-11-el_es_20090401-15-32-14_5.wav\tdata\\el_es\\es\\20090401-0900-PLENARY-11-el_es_20090401-15-32-14_5.wav\n",
        "\n",
        "data\\el_es\\el\\20090401-0900-PLENARY-11-el_es_20090401-16-03-40_1.wav\tdata\\el_es\\es\\20090401-0900-PLENARY-11-el_es_20090401-16-03-40_1.wav\n",
        "\n",
        "data\\el_es\\el\\20090401-0900-PLENARY-11-el_es_20090401-16-03-40_4.wav\tdata\\el_es\\es\\20090401-0900-PLENARY-11-el_es_20090401-16-03-40_4.wav\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "v9arLxlluSGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 **Data validation**"
      ],
      "metadata": {
        "id": "YcwBvKfkts2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyEbP7dw8R7-",
        "outputId": "26e8836e-7868-45c3-a9b4-8f4fd07eb490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "def clean(path):\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"Directory '{path}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    for filename in os.listdir(path):\n",
        "        file_path = os.path.join(path, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)  # remove file or symbolic link\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)  # remove directory and its contents\n",
        "            print(f\"> Deleted: {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[!]Failed to delete {file_path}. Reason: {e}\")"
      ],
      "metadata": {
        "id": "imMLtbdw9SJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_path = '/content/data'\n",
        "results_path = '/content/transcriptions'\n",
        "#clean(extract_path)\n",
        "#clean(results_path)\n",
        "\n",
        "el_data = '/content/drive/MyDrive/Colab Notebooks/el.zip'\n",
        "es_data = '/content/drive/MyDrive/Colab Notebooks/es.zip'\n",
        "el_transcripts = '/content/drive/MyDrive/Colab Notebooks/transcriptions/el.zip'\n",
        "es_transcripts = '/content/drive/MyDrive/Colab Notebooks/transcriptions/es.zip'\n",
        "\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(el_data, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "with zipfile.ZipFile(es_data, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extract_path)\n",
        "\n",
        "with zipfile.ZipFile(el_transcripts, 'r') as zip_ref:\n",
        "  zip_ref.extractall(results_path + \"/el\")\n",
        "\n",
        "with zipfile.ZipFile(es_transcripts, 'r') as zip_ref:\n",
        "  zip_ref.extractall(results_path + \"/es\")"
      ],
      "metadata": {
        "id": "UfsARnTw8YYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOdRvne227tk"
      },
      "outputs": [],
      "source": [
        "def load(lang):\n",
        "    \"\"\"Loads input audio data paths from data directory and sets up the\n",
        "    corresponding output data directories for the respective audio\n",
        "    language code(s).\"\"\"\n",
        "\n",
        "    dirs = {\"data\": \"./data\", \"output\": \"./transcriptions\"}\n",
        "    os.makedirs(dirs[\"output\"], exist_ok=True)\n",
        "\n",
        "    files = {lang: []}\n",
        "\n",
        "    out_lang_dir = os.path.join(dirs[\"output\"], lang)\n",
        "    os.makedirs(out_lang_dir, exist_ok=True)\n",
        "\n",
        "    lang_dir = os.path.join(dirs[\"data\"], lang)\n",
        "\n",
        "    if os.path.exists(lang_dir):\n",
        "      for f in os.listdir(lang_dir):\n",
        "        if f.startswith('.') or f.startswith('__') or f == '.ipynb_checkpoints':\n",
        "          continue\n",
        "\n",
        "        file_path = os.path.join(lang_dir, f)\n",
        "        output_path = os.path.join(out_lang_dir,\n",
        "                                              f.replace(\".wav\", \".json\"))\n",
        "\n",
        "        # for each audio file, we save its (input) path,\n",
        "        # corresponding output path, and language code\n",
        "        file_info = {\"input\": file_path,\n",
        "                              \"output\": output_path,\n",
        "                              \"lang\": lang}\n",
        "        files[lang].append(file_info)\n",
        "\n",
        "    return files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FVfX64UIgvy"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "def download(lang):\n",
        "    folder_path = f\"./{lang}\"\n",
        "    zip_path = f\"./{lang}.zip\"\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"❌ Directory {folder_path} does not exist.\")\n",
        "        return\n",
        "\n",
        "    shutil.make_archive(f\"./{lang}\", 'zip', folder_path)\n",
        "    try:\n",
        "        files.download(zip_path)\n",
        "        print(f\"⬇️ Download started for {zip_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to download {zip_path}: {e}\")\n",
        "    print(f\"✅ Downloaded transcriptions in [{lang}]!\")\n",
        "\n",
        "def export_json(result, input_file):\n",
        "    path = input_file[\"output\"]\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(result, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "def export_srt(result, input_file):\n",
        "    def format_timestamp(seconds):\n",
        "        hrs, rem = divmod(seconds, 3600)\n",
        "        mins, secs = divmod(rem, 60)\n",
        "        millis = (secs - int(secs)) * 1000\n",
        "        return f\"{int(hrs):02}:{int(mins):02}:{int(secs):02},{int(millis):03}\"\n",
        "\n",
        "    path = input_file[\"output\"].replace(\"json\", \"srt\");\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, segment in enumerate(result[\"segments\"]):\n",
        "            f.write(f\"{i+1}\\n\")\n",
        "            start = segment['start']\n",
        "            end = segment['end']\n",
        "            text = segment['text'].strip()\n",
        "            f.write(f\"{format_timestamp(start)} --> {format_timestamp(end)}\\n{text}\\n\\n\")\n",
        "\n",
        "def export_audacity(f):\n",
        "    srt_path = f[\"output\"].replace(\"json\", \"srt\")\n",
        "    out_path = f[\"output\"].replace(\".json\", \"_labels.txt\");\n",
        "\n",
        "    with open(srt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.read().splitlines()\n",
        "\n",
        "    entries = []\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        if lines[i].isdigit():\n",
        "            start, end = lines[i + 1].split(\" --> \")\n",
        "            text = lines[i + 2]\n",
        "\n",
        "            def to_sec(t):\n",
        "              import re\n",
        "              # HH:MM:SS,mmm with regex\n",
        "              match = re.match(r\"(\\d+):(\\d+):(\\d+),(\\d+)\", t)\n",
        "              if not match:\n",
        "                  raise ValueError(f\"Invalid timestamp format: {t}\")\n",
        "              h, m, s, ms = map(int, match.groups())\n",
        "              return h * 3600 + m * 60 + s + ms / 1000.0\n",
        "\n",
        "            entries.append(f\"{to_sec(start)}\\t{to_sec(end)}\\t{text}\")\n",
        "            i += 4  # next entry\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(entries))\n",
        "\n",
        "def export(result, f):\n",
        "  export_json(result, f)\n",
        "  export_srt(result, f)\n",
        "  export_audacity(f)\n",
        "  print(f\"💾 Saved transcriptions > {f['output'].replace('json', '*')}\\n\")\n",
        "\n",
        "def export_plain(f):\n",
        "    txt_path = f[\"output\"].replace(\"json\", \"txt\")\n",
        "    out_path = f[\"output\"].replace(\".json\", \"_plain.txt\");\n",
        "\n",
        "    with open(txt_path, 'r', encoding='utf-8') as inf, open(out_path, 'w', encoding='utf-8') as outf:\n",
        "        for line in inf:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) == 3:\n",
        "                outf.write(parts[2] + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Whisper**"
      ],
      "metadata": {
        "id": "c7YlFm2whRaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a maximum of 2 languages, it combines usage of both WhisperX for alignment and FasterWhisper for transcription.\n",
        "\n",
        "Transcription is done on a language-by-language basis, so only one model is loaded at once. This model can either be a 'large-v3', 'large-v2'... supported by Whisper itself, or a custom model from HuggingFace."
      ],
      "metadata": {
        "id": "O9nenBXHhW9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTvBiV85-TwC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import gc\n",
        "from faster_whisper import WhisperModel\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "\n",
        "# global settings\n",
        "audio = \".wav\"\n",
        "device = \"cpu\"\n",
        "compute = \"int8\"\n",
        "\n",
        "def setup(lang, model_name=\"large-v3\", is_custom=False):\n",
        "    \"\"\"Loads and sets up FasterWhisper and WhisperX model for transcription and alignment\n",
        "    of audio in a specific language.\"\"\"\n",
        "\n",
        "    print(f\"\\t💻 FasterWhisper model [{model_name}] for speech transcription in [{lang}]\")\n",
        "\n",
        "    if is_custom:\n",
        "      custom_model = WhisperForConditionalGeneration.from_pretrained(model_name, device_map=device)\n",
        "      custom_processor = WhisperProcessor.from_pretrained(model_name)\n",
        "      model = (custom_model, custom_processor)\n",
        "    else:\n",
        "      model = WhisperModel(model_name, device=device, compute_type=compute)\n",
        "\n",
        "    almodel, almetadata = whisperx.load_align_model(lang, device=device)\n",
        "    model = {\n",
        "        \"device\": device,\n",
        "        \"audio\": audio,\n",
        "        \"aligner\": (almodel.half(), almetadata),\n",
        "        \"model\": model,\n",
        "    }\n",
        "\n",
        "    return model\n",
        "\n",
        "def setdown(whisper_model, lang):\n",
        "    print(f\"💻 Setting down: Cleaning Whisper models and cache for [{lang}]...\\n\\n\")\n",
        "    del whisper_model[\"model\"]\n",
        "    del whisper_model[\"aligner\"]\n",
        "\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1zpSXaA_oSy"
      },
      "source": [
        "# **3. Transcribing audio**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr7DiSC9J-cB"
      },
      "source": [
        "Some functions for audio processing and normalization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00yUxXskJ9n7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torchaudio\n",
        "import tempfile\n",
        "from faster_whisper.vad import get_speech_timestamps, collect_chunks, VadOptions\n",
        "from pydub import AudioSegment\n",
        "from pathlib import Path\n",
        "\n",
        "def is_valid_wav(path):\n",
        "    try:\n",
        "        with open(path, 'rb') as f:\n",
        "            return f.read(4) == b'RIFF'\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def process_audio(path, target_sr = 16000, target_db = -20.0):\n",
        "    \"\"\"Loads and normalizes audio, returns waveform, duration, and saved path.\"\"\"\n",
        "    audio = AudioSegment.from_file(path)\n",
        "\n",
        "    change_in_dBFS = target_db - audio.dBFS\n",
        "    normalized = audio.apply_gain(change_in_dBFS)\n",
        "\n",
        "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "    normalized.export(temp_file.name, format=\"wav\")\n",
        "    temp_path = temp_file.name\n",
        "\n",
        "    waveform, sr = torchaudio.load(temp_path)\n",
        "    if sr != target_sr:\n",
        "        waveform = torchaudio.transforms.Resample(sr, target_sr)(waveform)\n",
        "    duration = len(audio) / 1000.0  # in seconds\n",
        "\n",
        "    return temp_path, duration, waveform\n",
        "\n",
        "def split_audio_file(path: str, chunk_ms: int = 10000, overlap_ms: int = 1000):\n",
        "    \"\"\"Splits audio into overlapping chunks (in ms). Returns [(path, offset)].\"\"\"\n",
        "    audio = AudioSegment.from_file(path)\n",
        "    chunks = []\n",
        "\n",
        "    for i in range(0, len(audio), chunk_ms - overlap_ms):\n",
        "        chunk = audio[i:i + chunk_ms]\n",
        "        offset_sec = i / 1000.0\n",
        "\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
        "        chunk.export(temp_file.name, format=\"wav\")\n",
        "        chunks.append((temp_file.name, offset_sec))\n",
        "\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNL6kid6ObNp"
      },
      "source": [
        "Transcription is done either in chunks (parallelized) or directly, either for a pretrained HuggingFace model or a Whisper-based one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wtQdmar-XUF"
      },
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def get_segments(model, audio_path, lang, is_custom, duration, th_s=30, chunk_size=10, batch_size=8, device=\"cuda\"):\n",
        "    # custom model\n",
        "    if is_custom:\n",
        "        custom_model, custom_processor = model\n",
        "        if device == \"cuda\":\n",
        "            custom_model = custom_model.half()\n",
        "        custom_model = custom_model.to(device)\n",
        "        return get_segments_custom(custom_model, custom_processor, audio_path, lang)\n",
        "\n",
        "    # too big audio\n",
        "    elif duration > th_s:\n",
        "      return get_segments_in_chunks(model, audio_path, lang)\n",
        "\n",
        "    # plain fasterwhisper transcription\n",
        "    with torch.no_grad():\n",
        "      segments, _ = model.transcribe(\n",
        "          audio_path,\n",
        "          language=lang,\n",
        "          beam_size=5,\n",
        "          #chunk_size=chunk_size,\n",
        "          #batch_size=batch_size\n",
        "      )\n",
        "\n",
        "    result = []\n",
        "    for seg in segments:\n",
        "        result.append({\n",
        "            \"start\": seg.start,\n",
        "            \"end\": seg.end,\n",
        "            \"text\": seg.text.strip()\n",
        "        })\n",
        "    return result\n",
        "\n",
        "def get_segments_custom(hf_model, processor, audio_path, lang, chunk_length_s=10):\n",
        "\n",
        "    speech_array, sampling_rate = torchaudio.load(audio_path)\n",
        "    resampler = torchaudio.transforms.Resample(sampling_rate, 16000)\n",
        "    speech_array = resampler(speech_array).squeeze().numpy()\n",
        "\n",
        "    chunk_size = int(chunk_length_s * 16000)\n",
        "    num_chunks = (len(speech_array) + chunk_size - 1) // chunk_size\n",
        "\n",
        "    segments = []\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        start = i * chunk_size\n",
        "        end = min(start + chunk_size, len(speech_array))\n",
        "        chunk = speech_array[start:end]\n",
        "\n",
        "        inputs = processor(chunk, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
        "        input_features = inputs.input_features\n",
        "        attention_mask = inputs.get(\"attention_mask\", None)\n",
        "\n",
        "        if hf_model.dtype == torch.float16:\n",
        "            input_features = input_features.half()\n",
        "        input_features = input_features.to(hf_model.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = attention_mask.to(hf_model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predicted_ids = hf_model.generate(\n",
        "                input_features,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=448,  # optional: control decoding length\n",
        "            )\n",
        "\n",
        "        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        segment = {\n",
        "            \"start\": start / 16000,  # start time in seconds\n",
        "            \"end\": end / 16000,      # end time in seconds\n",
        "            \"text\": transcription.strip()\n",
        "        }\n",
        "\n",
        "        segments.append(segment)\n",
        "\n",
        "    return segments\n",
        "\n",
        "def get_segments_in_chunks(model, path, lang, max_chunks=None, workers=4):\n",
        "    chunks = split_audio_file(path)\n",
        "    results = []\n",
        "    for idx, (chunk_path, offset) in tqdm(enumerate(chunks), total=min(len(chunks), max_chunks or len(chunks)), desc=\"chunk\"):\n",
        "        if max_chunks and idx >= max_chunks:\n",
        "            break\n",
        "\n",
        "        with torch.no_grad():\n",
        "            segs, _ = model.transcribe(chunk_path, language=lang)\n",
        "\n",
        "        for seg in segs:\n",
        "            results.append({\n",
        "                \"start\": seg.start + offset,\n",
        "                \"end\": seg.end + offset,\n",
        "                \"text\": seg.text.strip()\n",
        "            })\n",
        "\n",
        "        os.remove(chunk_path)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUuLUEDfQrZK"
      },
      "source": [
        "# **4. Transcribe**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each language, we load the respective model and input files, retrieve their transcriptions after processing the audio, and align the timestamped segments with the audios. These results are saved onto the respective output files."
      ],
      "metadata": {
        "id": "JKIxiZeFYMc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def whisper_transcribe(model, f, custom=False):\n",
        "    path, duration, audio = process_audio(f[\"input\"])\n",
        "    segments = get_segments(model[\"model\"], path, f[\"lang\"], custom, duration)\n",
        "    return segments, audio\n",
        "\n",
        "def whisper_align(model, segments, f, waveform):\n",
        "    \"\"\"Carries out alignment task with a given Whisper model, on an audio file.\"\"\"\n",
        "\n",
        "    align_model, metadata = model[\"aligner\"]\n",
        "    device = model[\"device\"]\n",
        "\n",
        "    if waveform.ndim == 1:\n",
        "        waveform = waveform.unsqueeze(0)\n",
        "\n",
        "    waveform = waveform.to(device=device, dtype=next(align_model.parameters()).dtype)\n",
        "\n",
        "    # alignment is done with whisperx\n",
        "    aligned_segments = whisperx.align(\n",
        "        segments,\n",
        "        align_model,\n",
        "        metadata,\n",
        "        waveform,\n",
        "        device=device,\n",
        "        return_char_alignments=False  # if not needed\n",
        "    )\n",
        "\n",
        "    #print(f\"📜 Transcribed and aligned {f['input']}, segments: {len(segments)}\")\n",
        "    return aligned_segments"
      ],
      "metadata": {
        "id": "CcxiueY2YKAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpQ2HgZYTkQQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a9f3fc5292b2487292c9bacc4725efef",
            "889a35085c774a82965ab886959a078b",
            "cfb41be96ea24c599667a8666c59d5a2",
            "6e50adbaa65141989c9ccc9479debbfe",
            "2ad41a4951074770ac640d70392c0a8f",
            "fc284c858a5e4acaaa7edcb5508088ab",
            "c50a0da1408e4f219684988a439a0507",
            "5be9880aa74c48d7a8d94656cfaee1e2",
            "270a6d16181344d4afaf30c9b92b528f",
            "9fe9a6f3e9e745f3ad520d7632af64b2",
            "b4e5894aa0ca486e8cdf4ee1905b6779",
            "f274bac8425c4554b9aed446e1dab23e",
            "f6afd8d0f75c4eb5aa2af483f57024ad",
            "ee27c7fc5c654259a9fc65f3b4ffed4c",
            "d854f2b3befa47c48d03d123df6ed6bf",
            "e42cf3c68f354b21a7a1b638231616f0",
            "be886db61c24417ea7b8fab5e5546f72",
            "cb31944feb1c41bda596e456d4be8d30",
            "f37abfa729b44222aff32b8104e8cebd",
            "d5eebc4893e44559ad33a35016b5010f",
            "94e730c00e264ca6a9e39e876709f581",
            "4aec732698f2445d81cf2b5b79578cce"
          ]
        },
        "outputId": "9f79f485-f485-427c-c086-eeb5d371c66e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t💻 FasterWhisper model [Systran/faster-whisper-large-v3] for speech transcription in [es]\n",
            "\n",
            "\t > 📛(!) Found 0 invalid WAV files in [es].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[es]:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9f3fc5292b2487292c9bacc4725efef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved transcriptions > ./transcriptions/es/20090916-0900-PLENARY-3-es_20090916-09-15-01_1.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090914-0900-PLENARY-14-es_20090914-19-31-32_9.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091215-0900-PLENARY-16-es_20091215-22-42-51_4.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090915-0900-PLENARY-10-es_20090915-17-38-36_7.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091125-0900-PLENARY-18-es_20091125-21-05-39_6.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090506-0900-PLENARY-12-es_20090506-16-39-17_6.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090401-0900-PLENARY-13-es_20090401-18-50-27_3.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090916-0900-PLENARY-3-es_20090916-10-09-51_9.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090715-0900-PLENARY-12-es_20090715-17-13-08_9.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090421-0900-PLENARY-17-es_20090421-21-56-13_14.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090916-0900-PLENARY-3-es_20090916-09-15-01_49.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091111-0900-PLENARY-11-es_20091111-17-15-49_0.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091123-0900-PLENARY-17-es_20091123-21-27-37_5.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091124-0900-PLENARY-19-es_20091124-23-34-31_1.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090506-0900-PLENARY-15-es_20090506-21-57-30_13.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090506-0900-PLENARY-11-es_20090506-15-31-07_15.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090504-0900-PLENARY-17-es_20090504-23-09-56_3.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091215-0900-PLENARY-16-es_20091215-22-47-32_8.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091125-0900-PLENARY-12-es_20091125-16-25-59_9.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090506-0900-PLENARY-15-es_20090506-21-57-30_0.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090916-0900-PLENARY-3-es_20090916-10-25-40_14.*\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chunk:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f274bac8425c4554b9aed446e1dab23e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved transcriptions > ./transcriptions/es/20090421-0900-PLENARY-17-es_20090421-22-18-31_0.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091215-0900-PLENARY-16-es_20091215-22-40-33_2.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090424-0900-PLENARY-4-es_20090424-09-40-44_3.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091215-0900-PLENARY-3-es_20091215-10-22-28_0.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091111-0900-PLENARY-11-es_20091111-17-28-50_0.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090504-0900-PLENARY-10-es_20090504-19-11-16_3.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091217-0900-PLENARY-7-es_20091217-11-42-08_0.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091020-0900-PLENARY-13-es_20091020-17-39-09_3.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091020-0900-PLENARY-4-es_20091020-10-39-16_2.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091215-0900-PLENARY-16-es_20091215-22-42-51_8.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20090917-0900-PLENARY-3-es_20090917-10-52-09_5.*\n",
            "\n",
            "💾 Saved transcriptions > ./transcriptions/es/20091123-0900-PLENARY-13-es_20091123-19-14-39_22.*\n",
            "\n",
            "💻 Setting down: Cleaning Whisper models and cache for [es]...\n",
            "\n",
            "\n",
            "❌ Directory ./es does not exist.\n"
          ]
        }
      ],
      "source": [
        "import whisperx\n",
        "\n",
        "langs_models = {\n",
        "    #\"el\": \"Sandiago21/whisper-large-v2-greek\",\n",
        "    \"es\": \"Systran/faster-whisper-large-v3\"\n",
        "}\n",
        "\n",
        "def transcribe_all(langs_models=langs_models):\n",
        "  for lang, name in langs_models.items():\n",
        "      # 1. load files for the language and check for their validity\n",
        "      files = load(lang)\n",
        "      invalid_files = [p for p in Path(f\"./data/{lang}\").glob(\"*.wav\") if not is_valid_wav(p)]\n",
        "      files = get_files_to_transcribe(files, lang)\n",
        "\n",
        "      # 2. load transcription and alignment model for the language\n",
        "      is_custom = (lang == \"el\")\n",
        "      whisper_model = setup(lang, model_name=name, is_custom=is_custom)\n",
        "      print(f\"\\n\\t > 📛(!) Found {len(invalid_files)} invalid WAV files in [{lang}].\")\n",
        "\n",
        "      # 3. transcribe + align for all files\n",
        "      for f in tqdm(files[lang], desc=f\"[{lang}]\"):\n",
        "\n",
        "        if Path(f['input']) not in invalid_files:\n",
        "            text, audio = whisper_transcribe(whisper_model, f, custom=is_custom)\n",
        "            a = whisper_align(whisper_model, text, f, audio)\n",
        "\n",
        "            # 4. save results for a file\n",
        "            export(a, f)\n",
        "        else:\n",
        "          print(f\"> ⚠️(!) Skipping transcription of invalid .wav file > {f['input']}\")\n",
        "\n",
        "      # 5. free memory\n",
        "      setdown(whisper_model, lang)\n",
        "\n",
        "      # 6. download results\n",
        "      download(lang)\n",
        "\n",
        "transcribe_all()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_files_to_transcribe(audio_files, lang, transcripts_dir=\"./transc_el/\"):\n",
        "    \"\"\"Filters the audio files to only include those for which corresponding transcripts already exist.\"\"\"\n",
        "    filtered_files = {f\"{lang}\" : []}\n",
        "\n",
        "    for file_info in audio_files.get(\"es\", []):\n",
        "        es_path = file_info[\"input\"]\n",
        "        filename = os.path.basename(es_path)\n",
        "\n",
        "        # Map the Spanish filename to the expected Greek transcription filename\n",
        "        base = filename.replace(\"-es_\", \"-el_es_\").replace(\".wav\", \"\")\n",
        "        json = os.path.join(transcripts_dir, base + \".json\")\n",
        "        srt = os.path.join(transcripts_dir, base + \".srt\")\n",
        "\n",
        "        if os.path.exists(json) and os.path.exists(srt):\n",
        "            filtered_files[lang].append(file_info)\n",
        "\n",
        "    return filtered_files"
      ],
      "metadata": {
        "id": "kIGJ6gYkAD4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Clean**\n",
        "\n",
        "Once transcriptions of all parallel audio files have been completed, clean them to remove any potential hallucinations or gibberish coming from faulty Whisper transcription."
      ],
      "metadata": {
        "id": "FKu0ki26NhCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or5JX42TjrVr",
        "outputId": "f1c52dec-56de-46e5-afdc-894e17f54d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysrt\n",
            "  Downloading pysrt-1.1.2.tar.gz (104 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.4/104.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from pysrt) (5.2.0)\n",
            "Building wheels for collected packages: pysrt\n",
            "  Building wheel for pysrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysrt: filename=pysrt-1.1.2-py3-none-any.whl size=13443 sha256=61aa053c6d1075e864dedd4dd4473c7fb953cad607636908fc2129d04e6e2693\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/b2/df/ea10959920533975b4a74a25a35e6d79655b63f3006611a99f\n",
            "Successfully built pysrt\n",
            "Installing collected packages: pysrt\n",
            "Successfully installed pysrt-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pysrt\n",
        "import os\n",
        "\n",
        "# audio files that have been transcribed\n",
        "es_files = load(\"es\")\n",
        "el_files = load(\"el\")\n",
        "\n",
        "audios = [es_files, el_files]\n",
        "langs = [\"es\", \"el\"]\n",
        "\n",
        "def get_clean_subdir(path):\n",
        "    dir_path, filename = os.path.split(path)\n",
        "    head, lang = os.path.split(dir_path)\n",
        "    new_dir = os.path.join(head, 'cleaned', lang)\n",
        "    os.makedirs(new_dir, exist_ok=True)\n",
        "    return os.path.join(new_dir, filename)\n",
        "\n",
        "\n",
        "def get_clean_transcriptions(audio_files, langs, transcripts_dir=\"./transcriptions/\", cleaned_dir=\"cleaned\"):\n",
        "    \"\"\"\n",
        "    Retrieves .srt transcription files that match the given audio files for a specific language.\n",
        "    \"\"\"\n",
        "    transc = {langs[0]: [], langs[1]: []}\n",
        "    os.makedirs(transcripts_dir + cleaned_dir, exist_ok=True)\n",
        "\n",
        "    for i, lang in enumerate(langs):\n",
        "      for file_info in audio_files[i].get(lang, []):\n",
        "          audio_path = file_info[\"input\"]\n",
        "          base = file_info[\"output\"].replace(\".json\",\"\")\n",
        "          filename = os.path.basename(audio_path)\n",
        "\n",
        "          srt_path = file_info[\"output\"].replace(\".json\",\".srt\")\n",
        "          txt_path = file_info[\"output\"].replace(\".json\",\".txt\")\n",
        "\n",
        "          output_srt_path = get_clean_subdir(srt_path)\n",
        "          output_txt_path = get_clean_subdir(txt_path)\n",
        "\n",
        "          if os.path.exists(srt_path):\n",
        "                # clean .srt file\n",
        "                subs = pysrt.open(srt_path, encoding='utf-8')\n",
        "                sentences = []\n",
        "                for sub in subs:\n",
        "                    cleaned = clean(sub.text)\n",
        "                    if cleaned and len(cleaned.split()) > 2:\n",
        "                        sentences.append(cleaned)\n",
        "\n",
        "                # save .srt file\n",
        "                with open(output_txt_path, 'w', encoding='utf-8') as out:\n",
        "                    out.write('\\n'.join(sentences))\n",
        "\n",
        "                # save file info\n",
        "                cleaned_file = {\"srt\": output_srt_path,\n",
        "                                \"txt\": output_txt_path,\n",
        "                                \"sentences\": sentences}\n",
        "                transc[lang].append(cleaned_file)\n",
        "\n",
        "    return transc\n",
        "\n",
        "def clean(text):\n",
        "    text = text.replace('\\n', ' ').strip()\n",
        "    text = text.replace('\\n', ' ').strip()\n",
        "    text = re.sub(r'(.)\\1{3,}', '', text)  # long repeated chars\n",
        "    text = re.sub(r'\\b(\\w+)(\\s+\\1\\b)+', r'\\1', text, flags=re.IGNORECASE)  # repeated words\n",
        "    text = re.sub(r'[^\\w\\s.,;!?¡¿-]', '', text, flags=re.UNICODE)  # allow Unicode words\n",
        "    return text.strip()\n",
        "\n",
        "transcriptions = get_clean_transcriptions(audios, langs)\n"
      ],
      "metadata": {
        "id": "Zvq8O7T_NrGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive('cleaned_transcriptions_es', 'zip', '/content/transcriptions/cleaned/es')\n",
        "files.download('cleaned_transcriptions_es.zip')\n",
        "\n",
        "shutil.make_archive('cleaned_transcriptions_el', 'zip', '/content/transcriptions/cleaned/el')\n",
        "files.download('cleaned_transcriptions_el.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rgNaclC7bMmT",
        "outputId": "27479473-bf21-45a1-9d8a-5b8c6e3d0768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb720d57-bdc0-4498-87bf-fe939b2f476a\", \"cleaned_transcriptions_es.zip\", 11165)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e1c9f65-dff1-40b7-a4b7-ac729b0f7b4a\", \"cleaned_transcriptions_el.zip\", 21562)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Align**\n",
        "\n",
        "Once transcriptions of all parallel audio files have been completed, carry out their respective alignment with HunAlign:"
      ],
      "metadata": {
        "id": "jd3lx0dg-F_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import subprocess\n",
        "\n",
        "def get_id(filepath):\n",
        "    filename = os.path.basename(filepath)\n",
        "    match = re.search(r'(\\d{8}-\\d{2}-\\d{2}-\\d{2}_\\d+)', filename)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def get_parallel_files(greek_files, spanish_files):\n",
        "    \"\"\"Match Greek and Spanish files based on shared identifier.\"\"\"\n",
        "    greek_map = {get_id(g['srt']): g for g in greek_files}\n",
        "    spanish_map = {get_id(s['srt']): s for s in spanish_files}\n",
        "\n",
        "    matches = []\n",
        "    for identifier, greek_file in greek_map.items():\n",
        "        spanish_file = spanish_map.get(identifier)\n",
        "        if spanish_file:\n",
        "            matches.append((greek_file, spanish_file))\n",
        "\n",
        "    return matches\n",
        "\n",
        "\n",
        "def hun_align(transc, dictionary_dir=\"/dev/null\", output_dir=\"./aligned/\", min_score=0.85, hun_exe=\"hunalign-1.1/src/hunalign/hunalign\"):\n",
        "    \"\"\"Aligns Greek-Spanish sentence pairs from cleaned transcriptions using HunAlign.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    aligned_results = []\n",
        "    al_path = os.path.join(output_dir, \"alignments.txt\")\n",
        "\n",
        "    parallel = get_parallel_files(transc[\"el\"], transc[\"es\"])\n",
        "\n",
        "    for el_info, es_info in parallel:\n",
        "        base_name = os.path.splitext(os.path.basename(el_info[\"txt\"]))[0]\n",
        "        out_path = os.path.join(output_dir, base_name + \".aligned.txt\")\n",
        "\n",
        "        command = [\n",
        "            hun_exe, dictionary_dir, \"-text\",\n",
        "            es_info[\"txt\"], el_info[\"txt\"]\n",
        "        ]\n",
        "\n",
        "        with open(out_path, \"w\", encoding=\"utf-8\") as out_file:\n",
        "            result = subprocess.run(command, stdout=out_file, stderr=subprocess.PIPE)\n",
        "\n",
        "        # parse output\n",
        "        with open(out_path, \"r\", encoding=\"utf-8\") as aligned_file:\n",
        "            for line in aligned_file:\n",
        "                if \"|||\" not in line:\n",
        "                    continue\n",
        "                parts = line.strip().split(\"|||\")\n",
        "                if len(parts) != 3:\n",
        "                    continue\n",
        "                try:\n",
        "                    score = float(parts[0].strip())\n",
        "                    if score < min_score:\n",
        "                        continue\n",
        "                    es_sent = parts[1].strip()\n",
        "                    el_sent = parts[2].strip()\n",
        "                    aligned_results.append((base_name, score, es_sent, el_sent))\n",
        "\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    with open(al_path, \"w\", encoding=\"utf-8\") as out:\n",
        "      out.write(\"file\\tscore\\tes\\tsel\\n\")\n",
        "      for fname, score, es, el in aligned_results:\n",
        "        out.write(f\"{fname}\\t{score:.2f}\\t{es}\\t{el}\\n\")\n",
        "\n",
        "    return aligned_results\n",
        "\n",
        "hun_align(transcriptions)\n",
        "shutil.make_archive('alignments', 'zip', '/content/aligned')\n",
        "files.download('alignments.zip')"
      ],
      "metadata": {
        "id": "7oe1rCAD6iti",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0fd14090-79fc-4d41-85f9-c0b0aec1cae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_eb2e3698-688c-4473-b1c7-3437b18c21e4\", \"alignments.zip\", 19130)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9f3fc5292b2487292c9bacc4725efef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_889a35085c774a82965ab886959a078b",
              "IPY_MODEL_cfb41be96ea24c599667a8666c59d5a2",
              "IPY_MODEL_6e50adbaa65141989c9ccc9479debbfe"
            ],
            "layout": "IPY_MODEL_2ad41a4951074770ac640d70392c0a8f"
          }
        },
        "889a35085c774a82965ab886959a078b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc284c858a5e4acaaa7edcb5508088ab",
            "placeholder": "​",
            "style": "IPY_MODEL_c50a0da1408e4f219684988a439a0507",
            "value": "[es]: 100%"
          }
        },
        "cfb41be96ea24c599667a8666c59d5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5be9880aa74c48d7a8d94656cfaee1e2",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_270a6d16181344d4afaf30c9b92b528f",
            "value": 33
          }
        },
        "6e50adbaa65141989c9ccc9479debbfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fe9a6f3e9e745f3ad520d7632af64b2",
            "placeholder": "​",
            "style": "IPY_MODEL_b4e5894aa0ca486e8cdf4ee1905b6779",
            "value": " 33/33 [1:38:27&lt;00:00, 125.55s/it]"
          }
        },
        "2ad41a4951074770ac640d70392c0a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc284c858a5e4acaaa7edcb5508088ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c50a0da1408e4f219684988a439a0507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5be9880aa74c48d7a8d94656cfaee1e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "270a6d16181344d4afaf30c9b92b528f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fe9a6f3e9e745f3ad520d7632af64b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e5894aa0ca486e8cdf4ee1905b6779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f274bac8425c4554b9aed446e1dab23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6afd8d0f75c4eb5aa2af483f57024ad",
              "IPY_MODEL_ee27c7fc5c654259a9fc65f3b4ffed4c",
              "IPY_MODEL_d854f2b3befa47c48d03d123df6ed6bf"
            ],
            "layout": "IPY_MODEL_e42cf3c68f354b21a7a1b638231616f0"
          }
        },
        "f6afd8d0f75c4eb5aa2af483f57024ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be886db61c24417ea7b8fab5e5546f72",
            "placeholder": "​",
            "style": "IPY_MODEL_cb31944feb1c41bda596e456d4be8d30",
            "value": "chunk: 100%"
          }
        },
        "ee27c7fc5c654259a9fc65f3b4ffed4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f37abfa729b44222aff32b8104e8cebd",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5eebc4893e44559ad33a35016b5010f",
            "value": 4
          }
        },
        "d854f2b3befa47c48d03d123df6ed6bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94e730c00e264ca6a9e39e876709f581",
            "placeholder": "​",
            "style": "IPY_MODEL_4aec732698f2445d81cf2b5b79578cce",
            "value": " 4/4 [00:55&lt;00:00, 13.27s/it]"
          }
        },
        "e42cf3c68f354b21a7a1b638231616f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be886db61c24417ea7b8fab5e5546f72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb31944feb1c41bda596e456d4be8d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f37abfa729b44222aff32b8104e8cebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5eebc4893e44559ad33a35016b5010f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94e730c00e264ca6a9e39e876709f581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aec732698f2445d81cf2b5b79578cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}